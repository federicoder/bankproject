number of rows, number of columns 
(10000, 14)
--------------------------------------------
Check column list and missing values:
RowNumber          0
CustomerId         0
Surname            0
CreditScore        0
Geography          0
Gender             0
Age                0
Tenure             0
Balance            0
NumOfProducts      0
HasCrCard          0
IsActiveMember     0
EstimatedSalary    0
Exited             0
dtype: int64
--------------------------------------------
Get unique count for each variable:
RowNumber          10000
CustomerId         10000
Surname             2932
CreditScore          460
Geography              3
Gender                 2
Age                   70
Tenure                11
Balance             6382
NumOfProducts          4
HasCrCard              2
IsActiveMember         2
EstimatedSalary     9999
Exited                 2
dtype: int64
--------------------------------------------
Get duplicated data:
Empty DataFrame
Columns: [RowNumber, CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]
Index: []
--------------------------------------------
Check variable data types:
RowNumber            int64
CustomerId           int64
Surname             object
CreditScore          int64
Geography           object
Gender              object
Age                  int64
Tenure               int64
Balance            float64
NumOfProducts        int64
HasCrCard            int64
IsActiveMember       int64
EstimatedSalary    float64
Exited               int64
dtype: object
--------------------------------------------
First five rows of the dataset:
   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \
0          1    15634602  Hargrave          619    France  Female   42   
1          2    15647311      Hill          608     Spain  Female   41   
2          3    15619304      Onio          502    France  Female   42   
3          4    15701354      Boni          699    France  Female   39   
4          5    15737888  Mitchell          850     Spain  Female   43   

   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \
0       2       0.00              1          1               1   
1       1   83807.86              1          0               1   
2       8  159660.80              3          1               0   
3       1       0.00              2          0               0   
4       2  125510.82              1          1               1   

   EstimatedSalary  Exited  
0        101348.88       1  
1        112542.58       0  
2        113931.57       1  
3         93826.63       0  
4         79084.10       0  
--------------------------------------------
Total number of rows for the Training set and the Test set:
8000
2000
--------------------------------------------
First five rows of the Training Set with the new Features:
      CreditScore Geography  Gender  Age  Tenure  Balance  NumOfProducts  \
6252          596   Germany    Male   32       3    96709              2   
4684          623    France    Male   43       1        0              2   
1731          601     Spain  Female   44       4        0              2   
4742          506   Germany    Male   59       8   119152              2   
4521          560     Spain  Female   27       7   124995              1   

      HasCrCard  IsActiveMember  EstimatedSalary  Exited  BalanceSalaryRatio  \
6252          0               0            41788       0            2.314277   
4684          1               1           146379       0            0.000000   
1731          1               0            58561       0            0.000000   
4742          1               1           170679       0            0.698106   
4521          1               1           114669       0            1.090050   

      TenureByAge  CreditScoreGivenAge  
6252     0.093750            18.625000  
4684     0.023256            14.488372  
1731     0.090909            13.659091  
4742     0.135593             8.576271  
4521     0.259259            20.740741  
--------------------------------------------
detecting outliers:

First five rows of the Reordered Training Set:
      Exited  CreditScore  Age  Tenure  Balance  NumOfProducts  \
6252       0          596   32       3    96709              2   
4684       0          623   43       1        0              2   
1731       0          601   44       4        0              2   
4742       0          506   59       8   119152              2   
4521       0          560   27       7   124995              1   

      EstimatedSalary  BalanceSalaryRatio  TenureByAge  CreditScoreGivenAge  \
6252            41788            2.314277     0.093750            18.625000   
4684           146379            0.000000     0.023256            14.488372   
1731            58561            0.000000     0.090909            13.659091   
4742           170679            0.698106     0.135593             8.576271   
4521           114669            1.090050     0.259259            20.740741   

      HasCrCard  IsActiveMember Geography  Gender  
6252          0               0   Germany    Male  
4684          1               1    France    Male  
1731          1               0     Spain  Female  
4742          1               1   Germany    Male  
4521          1               1     Spain  Female  
--------------------------------------------
First five rows of the Training Set after changing the HasCrCard and IsActiveMember values from 0 to -1:
      Exited  CreditScore  Age  Tenure  Balance  NumOfProducts  \
6252       0          596   32       3    96709              2   
4684       0          623   43       1        0              2   
1731       0          601   44       4        0              2   
4742       0          506   59       8   119152              2   
4521       0          560   27       7   124995              1   

      EstimatedSalary  BalanceSalaryRatio  TenureByAge  CreditScoreGivenAge  \
6252            41788            2.314277     0.093750            18.625000   
4684           146379            0.000000     0.023256            14.488372   
1731            58561            0.000000     0.090909            13.659091   
4742           170679            0.698106     0.135593             8.576271   
4521           114669            1.090050     0.259259            20.740741   

      HasCrCard  IsActiveMember Geography  Gender  
6252         -1              -1   Germany    Male  
4684          1               1    France    Male  
1731          1              -1     Spain  Female  
4742          1               1   Germany    Male  
4521          1               1     Spain  Female  
--------------------------------------------
First five rows of the Training Set after One Hot Encoding:
      Exited  CreditScore  Age  Tenure  Balance  NumOfProducts  \
6252       0          596   32       3    96709              2   
4684       0          623   43       1        0              2   
1731       0          601   44       4        0              2   
4742       0          506   59       8   119152              2   
4521       0          560   27       7   124995              1   

      EstimatedSalary  BalanceSalaryRatio  TenureByAge  CreditScoreGivenAge  \
6252            41788            2.314277     0.093750            18.625000   
4684           146379            0.000000     0.023256            14.488372   
1731            58561            0.000000     0.090909            13.659091   
4742           170679            0.698106     0.135593             8.576271   
4521           114669            1.090050     0.259259            20.740741   

      HasCrCard  IsActiveMember  Geography_Germany  Geography_France  \
6252         -1              -1                  1                -1   
4684          1               1                 -1                 1   
1731          1              -1                 -1                -1   
4742          1               1                  1                -1   
4521          1               1                 -1                -1   

      Geography_Spain  Gender_Male  Gender_Female  
6252               -1            1             -1  
4684               -1            1             -1  
1731                1           -1              1  
4742               -1            1             -1  
4521                1           -1              1  
--------------------------------------------
Min-Max normalization:

First five rows of the Training Set after min-max normalization:
      Exited  CreditScore       Age  Tenure   Balance  NumOfProducts  \
6252       0        0.492  0.189189     0.3  0.385451       0.333333   
4684       0        0.546  0.337838     0.1  0.000000       0.333333   
1731       0        0.502  0.351351     0.4  0.000000       0.333333   
4742       0        0.312  0.554054     0.8  0.474902       0.333333   
4521       0        0.420  0.121622     0.7  0.498190       0.000000   

      EstimatedSalary  BalanceSalaryRatio  TenureByAge  CreditScoreGivenAge  \
6252         0.208905            0.000207     0.168750             0.311633   
4684         0.731910            0.000000     0.041860             0.210886   
1731         0.292778            0.000000     0.163636             0.190689   
4742         0.853421            0.000062     0.244068             0.066896   
4521         0.573344            0.000098     0.466667             0.363162   

      HasCrCard  IsActiveMember  Geography_Germany  Geography_France  \
6252         -1              -1                  1                -1   
4684          1               1                 -1                 1   
1731          1              -1                 -1                -1   
4742          1               1                  1                -1   
4521          1               1                 -1                -1   

      Geography_Spain  Gender_Male  Gender_Female  
6252               -1            1             -1  
4684               -1            1             -1  
1731                1           -1              1  
4742               -1            1             -1  
4521                1           -1              1  
--------------------------------------------
Total number of rows for the Training set and the Test set:
7963
--------------------------------------------
First five rows of the Reordered Training Set For GMM:
      Exited  CreditScore       Age  Tenure   Balance  NumOfProducts  \
6252       0        0.492  0.189189     0.3  0.385451       0.333333   
4684       0        0.546  0.337838     0.1  0.000000       0.333333   
1731       0        0.502  0.351351     0.4  0.000000       0.333333   
4742       0        0.312  0.554054     0.8  0.474902       0.333333   
4521       0        0.420  0.121622     0.7  0.498190       0.000000   

      EstimatedSalary  BalanceSalaryRatio  TenureByAge  CreditScoreGivenAge  \
6252         0.208905            0.000207     0.168750             0.311633   
4684         0.731910            0.000000     0.041860             0.210886   
1731         0.292778            0.000000     0.163636             0.190689   
4742         0.853421            0.000062     0.244068             0.066896   
4521         0.573344            0.000098     0.466667             0.363162   

      HasCrCard  IsActiveMember  Geography_Germany  Geography_France  \
6252         -1              -1                  1                -1   
4684          1               1                 -1                 1   
1731          1              -1                 -1                -1   
4742          1               1                  1                -1   
4521          1               1                 -1                -1   

      Geography_Spain  Gender_Male  Gender_Female  
6252               -1            1             -1  
4684               -1            1             -1  
1731                1           -1              1  
4742               -1            1             -1  
4521                1           -1              1  
--------------------------------------------
Min-Max normalization:

Model Fit and Selection Phase:

CV of Logistic Regression:

hyperparameter tuning for logistic regression:

Best score of model:
0.8139999999999998 

Best params of model:
{'C': 100, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 250, 'penalty': 'l2', 'tol': 1e-05} 

Best estimator of model:
LogisticRegression(C=100, max_iter=250, tol=1e-05) 

--------------------------------------------
hyperparameter tuning for SVM:

Best score of model:
0.8541255111303135 

Best params of model:
{'C': 100, 'gamma': 0.1, 'kernel': 'rbf', 'probability': True} 

Best estimator of model:
SVC(C=100, gamma=0.1, probability=True) 

--------------------------------------------
Fit Decision Tree Classifier with max depth 8 setted:

Fitting 5 folds for each of 4 candidates, totalling 20 fits
[CV 1/5] END .....criterion=gini, splitter=best;, score=0.844 total time=   0.0s
[CV 2/5] END .....criterion=gini, splitter=best;, score=0.861 total time=   0.0s
[CV 3/5] END .....criterion=gini, splitter=best;, score=0.843 total time=   0.0s
[CV 4/5] END .....criterion=gini, splitter=best;, score=0.854 total time=   0.0s
[CV 5/5] END .....criterion=gini, splitter=best;, score=0.838 total time=   0.0s
[CV 1/5] END ...criterion=gini, splitter=random;, score=0.851 total time=   0.0s
[CV 2/5] END ...criterion=gini, splitter=random;, score=0.860 total time=   0.0s
[CV 3/5] END ...criterion=gini, splitter=random;, score=0.851 total time=   0.0s
[CV 4/5] END ...criterion=gini, splitter=random;, score=0.853 total time=   0.0s
[CV 5/5] END ...criterion=gini, splitter=random;, score=0.851 total time=   0.0s
[CV 1/5] END ..criterion=entropy, splitter=best;, score=0.848 total time=   0.0s
[CV 2/5] END ..criterion=entropy, splitter=best;, score=0.862 total time=   0.0s
[CV 3/5] END ..criterion=entropy, splitter=best;, score=0.846 total time=   0.0s
[CV 4/5] END ..criterion=entropy, splitter=best;, score=0.861 total time=   0.0s
[CV 5/5] END ..criterion=entropy, splitter=best;, score=0.842 total time=   0.0s
[CV 1/5] END criterion=entropy, splitter=random;, score=0.834 total time=   0.0s
[CV 2/5] END criterion=entropy, splitter=random;, score=0.854 total time=   0.0s
[CV 3/5] END criterion=entropy, splitter=random;, score=0.838 total time=   0.0s
[CV 4/5] END criterion=entropy, splitter=random;, score=0.859 total time=   0.0s
[CV 5/5] END criterion=entropy, splitter=random;, score=0.853 total time=   0.0s
hyperparameter tuning for Decision Tree:

Best score of model:
0.853125 

Best params of model:
{'criterion': 'gini', 'splitter': 'random'} 

Best estimator of model:
DecisionTreeClassifier(max_depth=8, random_state=200, splitter='random') 

--------------------------------------------
Fitting 5 folds for each of 80 candidates, totalling 400 fits
[CV 1/5] END algorithm=auto, n_neighbors=1, p=1, weights=uniform;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=1, p=1, weights=uniform;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=1, p=1, weights=uniform;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=1, p=1, weights=distance;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=1, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=1, p=1, weights=distance;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=1, p=2, weights=uniform;, score=0.781 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=1, p=2, weights=uniform;, score=0.769 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=1, p=2, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=1, p=2, weights=uniform;, score=0.784 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=1, p=2, weights=uniform;, score=0.758 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=1, p=2, weights=distance;, score=0.781 total time=   0.0s
[CV 2/5] END algorithm=auto, n_neighbors=1, p=2, weights=distance;, score=0.769 total time=   0.0s
[CV 3/5] END algorithm=auto, n_neighbors=1, p=2, weights=distance;, score=0.772 total time=   0.0s
[CV 4/5] END algorithm=auto, n_neighbors=1, p=2, weights=distance;, score=0.784 total time=   0.0s
[CV 5/5] END algorithm=auto, n_neighbors=1, p=2, weights=distance;, score=0.758 total time=   0.0s
[CV 1/5] END algorithm=auto, n_neighbors=2, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=2, p=1, weights=uniform;, score=0.812 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=2, p=1, weights=uniform;, score=0.803 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=2, p=1, weights=distance;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=2, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=2, p=1, weights=distance;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=2, p=2, weights=uniform;, score=0.812 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=2, p=2, weights=uniform;, score=0.811 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=2, p=2, weights=uniform;, score=0.805 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=2, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=2, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=2, p=2, weights=distance;, score=0.781 total time=   0.0s
[CV 2/5] END algorithm=auto, n_neighbors=2, p=2, weights=distance;, score=0.769 total time=   0.0s
[CV 3/5] END algorithm=auto, n_neighbors=2, p=2, weights=distance;, score=0.772 total time=   0.0s
[CV 4/5] END algorithm=auto, n_neighbors=2, p=2, weights=distance;, score=0.784 total time=   0.0s
[CV 5/5] END algorithm=auto, n_neighbors=2, p=2, weights=distance;, score=0.758 total time=   0.0s
[CV 1/5] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=0.807 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=0.810 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=0.817 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=3, p=1, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=0.803 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=0.806 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=0.813 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=3, p=1, weights=distance;, score=0.802 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=0.801 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=0.810 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=3, p=2, weights=uniform;, score=0.789 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.0s
[CV 2/5] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=0.796 total time=   0.0s
[CV 3/5] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=0.808 total time=   0.0s
[CV 4/5] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.0s
[CV 5/5] END algorithm=auto, n_neighbors=3, p=2, weights=distance;, score=0.791 total time=   0.0s
[CV 1/5] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.821 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=4, p=1, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.809 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.807 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.812 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=4, p=1, weights=distance;, score=0.801 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.817 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=4, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.811 total time=   0.0s
[CV 2/5] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.801 total time=   0.0s
[CV 3/5] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.815 total time=   0.0s
[CV 4/5] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.810 total time=   0.0s
[CV 5/5] END algorithm=auto, n_neighbors=4, p=2, weights=distance;, score=0.792 total time=   0.0s
[CV 1/5] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.820 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.825 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=5, p=1, weights=uniform;, score=0.808 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.821 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=5, p=1, weights=distance;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 3/5] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 4/5] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.816 total time=   0.1s
[CV 5/5] END algorithm=auto, n_neighbors=5, p=2, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.817 total time=   0.0s
[CV 2/5] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.812 total time=   0.0s
[CV 3/5] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.826 total time=   0.0s
[CV 4/5] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.816 total time=   0.0s
[CV 5/5] END algorithm=auto, n_neighbors=5, p=2, weights=distance;, score=0.808 total time=   0.0s
[CV 1/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=uniform;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=uniform;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=uniform;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=distance;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=distance;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=uniform;, score=0.781 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=uniform;, score=0.769 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=uniform;, score=0.784 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=uniform;, score=0.758 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=distance;, score=0.781 total time=   0.0s
[CV 2/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=distance;, score=0.769 total time=   0.0s
[CV 3/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=distance;, score=0.772 total time=   0.0s
[CV 4/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=distance;, score=0.784 total time=   0.0s
[CV 5/5] END algorithm=ball_tree, n_neighbors=1, p=2, weights=distance;, score=0.758 total time=   0.0s
[CV 1/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=uniform;, score=0.812 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=uniform;, score=0.803 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=distance;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=distance;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=uniform;, score=0.812 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=uniform;, score=0.811 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=uniform;, score=0.805 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=distance;, score=0.781 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=distance;, score=0.769 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=distance;, score=0.784 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=2, p=2, weights=distance;, score=0.758 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=0.807 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=0.810 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=0.817 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=0.803 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=0.806 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=0.813 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=3, p=1, weights=distance;, score=0.802 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=0.801 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=0.810 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=uniform;, score=0.789 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=0.796 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=0.808 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=3, p=2, weights=distance;, score=0.791 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.821 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.809 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.807 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.812 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=4, p=1, weights=distance;, score=0.801 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.817 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.801 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.810 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=4, p=2, weights=distance;, score=0.792 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.820 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.825 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=uniform;, score=0.808 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.821 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=5, p=1, weights=distance;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.816 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.817 total time=   0.1s
[CV 2/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.812 total time=   0.1s
[CV 3/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.826 total time=   0.1s
[CV 4/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.816 total time=   0.1s
[CV 5/5] END algorithm=ball_tree, n_neighbors=5, p=2, weights=distance;, score=0.808 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=uniform;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=uniform;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=uniform;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=distance;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=distance;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=uniform;, score=0.781 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=uniform;, score=0.769 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=uniform;, score=0.784 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=uniform;, score=0.758 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=distance;, score=0.781 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=distance;, score=0.769 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=distance;, score=0.784 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=1, p=2, weights=distance;, score=0.758 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=uniform;, score=0.812 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=uniform;, score=0.803 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=distance;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=distance;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=uniform;, score=0.812 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=uniform;, score=0.811 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=uniform;, score=0.805 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=distance;, score=0.781 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=distance;, score=0.769 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=distance;, score=0.784 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=2, p=2, weights=distance;, score=0.758 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=0.807 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=0.810 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=0.817 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=0.803 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=0.806 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=0.813 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=3, p=1, weights=distance;, score=0.802 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=0.801 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=0.810 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=uniform;, score=0.789 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=0.796 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=0.808 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=3, p=2, weights=distance;, score=0.791 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.821 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.2s
[CV 4/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.809 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.807 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.812 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=4, p=1, weights=distance;, score=0.801 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.817 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.801 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.810 total time=   0.2s
[CV 5/5] END algorithm=kd_tree, n_neighbors=4, p=2, weights=distance;, score=0.792 total time=   0.3s
[CV 1/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.820 total time=   0.2s
[CV 2/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.815 total time=   0.2s
[CV 4/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.825 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=uniform;, score=0.808 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.821 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=5, p=1, weights=distance;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.816 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.817 total time=   0.1s
[CV 2/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.812 total time=   0.1s
[CV 3/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.826 total time=   0.1s
[CV 4/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.816 total time=   0.1s
[CV 5/5] END algorithm=kd_tree, n_neighbors=5, p=2, weights=distance;, score=0.808 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=1, p=1, weights=uniform;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=1, p=1, weights=uniform;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=1, p=1, weights=uniform;, score=0.780 total time=   0.3s
[CV 5/5] END algorithm=brute, n_neighbors=1, p=1, weights=uniform;, score=0.772 total time=   0.4s
[CV 1/5] END algorithm=brute, n_neighbors=1, p=1, weights=distance;, score=0.791 total time=   0.3s
[CV 2/5] END algorithm=brute, n_neighbors=1, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=1, p=1, weights=distance;, score=0.780 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=1, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=1, p=2, weights=uniform;, score=0.781 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=1, p=2, weights=uniform;, score=0.769 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=1, p=2, weights=uniform;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=1, p=2, weights=uniform;, score=0.784 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=1, p=2, weights=uniform;, score=0.758 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=1, p=2, weights=distance;, score=0.781 total time=   0.0s
[CV 2/5] END algorithm=brute, n_neighbors=1, p=2, weights=distance;, score=0.769 total time=   0.0s
[CV 3/5] END algorithm=brute, n_neighbors=1, p=2, weights=distance;, score=0.772 total time=   0.0s
[CV 4/5] END algorithm=brute, n_neighbors=1, p=2, weights=distance;, score=0.784 total time=   0.0s
[CV 5/5] END algorithm=brute, n_neighbors=1, p=2, weights=distance;, score=0.758 total time=   0.0s
[CV 1/5] END algorithm=brute, n_neighbors=2, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=2, p=1, weights=uniform;, score=0.812 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=2, p=1, weights=uniform;, score=0.803 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=2, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=2, p=1, weights=distance;, score=0.791 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=2, p=1, weights=distance;, score=0.773 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=2, p=1, weights=distance;, score=0.780 total time=   0.2s
[CV 5/5] END algorithm=brute, n_neighbors=2, p=1, weights=distance;, score=0.772 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=2, p=2, weights=uniform;, score=0.812 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=2, p=2, weights=uniform;, score=0.811 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=2, p=2, weights=uniform;, score=0.805 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=2, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=2, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=2, p=2, weights=distance;, score=0.781 total time=   0.5s
[CV 2/5] END algorithm=brute, n_neighbors=2, p=2, weights=distance;, score=0.769 total time=   0.0s
[CV 3/5] END algorithm=brute, n_neighbors=2, p=2, weights=distance;, score=0.772 total time=   0.0s
[CV 4/5] END algorithm=brute, n_neighbors=2, p=2, weights=distance;, score=0.784 total time=   0.0s
[CV 5/5] END algorithm=brute, n_neighbors=2, p=2, weights=distance;, score=0.758 total time=   0.0s
[CV 1/5] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=0.807 total time=   0.4s
[CV 3/5] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=0.810 total time=   0.7s
[CV 4/5] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=0.817 total time=   0.2s
[CV 5/5] END algorithm=brute, n_neighbors=3, p=1, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=0.811 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=0.803 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=0.806 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=0.813 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=3, p=1, weights=distance;, score=0.802 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=0.801 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=0.810 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=0.807 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=3, p=2, weights=uniform;, score=0.789 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.0s
[CV 2/5] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=0.796 total time=   0.0s
[CV 3/5] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=0.808 total time=   0.0s
[CV 4/5] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=0.806 total time=   0.0s
[CV 5/5] END algorithm=brute, n_neighbors=3, p=2, weights=distance;, score=0.791 total time=   0.0s
[CV 1/5] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.821 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.818 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=4, p=1, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.809 total time=   0.2s
[CV 3/5] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.807 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.812 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=4, p=1, weights=distance;, score=0.801 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.814 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.817 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=4, p=2, weights=uniform;, score=0.804 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.811 total time=   0.0s
[CV 2/5] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.801 total time=   0.0s
[CV 3/5] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.815 total time=   0.0s
[CV 4/5] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.810 total time=   0.0s
[CV 5/5] END algorithm=brute, n_neighbors=4, p=2, weights=distance;, score=0.792 total time=   0.0s
[CV 1/5] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.820 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.814 total time=   0.3s
[CV 3/5] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.815 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.825 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=5, p=1, weights=uniform;, score=0.808 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.818 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.816 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.821 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=5, p=1, weights=distance;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.818 total time=   0.1s
[CV 2/5] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.806 total time=   0.1s
[CV 3/5] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.819 total time=   0.1s
[CV 4/5] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.816 total time=   0.1s
[CV 5/5] END algorithm=brute, n_neighbors=5, p=2, weights=uniform;, score=0.809 total time=   0.1s
[CV 1/5] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.817 total time=   0.0s
[CV 2/5] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.812 total time=   0.0s
[CV 3/5] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.826 total time=   0.0s
[CV 4/5] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.816 total time=   0.0s
[CV 5/5] END algorithm=brute, n_neighbors=5, p=2, weights=distance;, score=0.808 total time=   0.0s
hyperparameter tuning for KNN:

Best score of model:
0.8163750000000001 

Best params of model:
{'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'} 

Best estimator of model:
KNeighborsClassifier(p=1) 

--------------------------------------------
hyperparameter tuning for Random Forest:

Best score of model:
0.86 

Best params of model:
{'max_depth': 5, 'max_features': 6} 

Best estimator of model:
RandomForestClassifier(max_depth=5, max_features=6, min_samples_split=4,
                       n_estimators=50) 

--------------------------------------------
hyperparameter tuning for XGB:

Best score of model:
0.8658750000000002 

Best params of model:
{'gamma': 0.001, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 10} 

Best estimator of model:
XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,
              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, gamma=0.001, gpu_id=-1, grow_policy='depthwise',
              importance_type=None, interaction_constraints='',
              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=10,
              missing=nan, monotone_constraints='()', n_estimators=100,
              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,
              reg_alpha=0, reg_lambda=1, ...) 

--------------------------------------------
Fitting 6 folds for each of 4 candidates, totalling 24 fits
[CV 1/6] END ...................n_components=1;, score=10.753 total time=   0.2s
[CV 2/6] END ...................n_components=1;, score=10.813 total time=   0.2s
[CV 3/6] END ...................n_components=1;, score=10.520 total time=   0.2s
[CV 4/6] END ...................n_components=1;, score=10.861 total time=   0.2s
[CV 5/6] END ...................n_components=1;, score=10.879 total time=   0.2s
[CV 6/6] END ...................n_components=1;, score=10.252 total time=   0.2s
[CV 1/6] END ...................n_components=2;, score=17.742 total time=   0.2s
[CV 2/6] END ...................n_components=2;, score=17.841 total time=   0.3s
[CV 3/6] END ...................n_components=2;, score=17.625 total time=   0.2s
[CV 4/6] END ...................n_components=2;, score=21.563 total time=   0.2s
[CV 5/6] END ...................n_components=2;, score=17.877 total time=   0.2s
[CV 6/6] END ...................n_components=2;, score=17.361 total time=   0.3s
[CV 1/6] END ...................n_components=3;, score=22.585 total time=   0.7s
[CV 2/6] END ...................n_components=3;, score=23.424 total time=   0.4s
[CV 3/6] END ...................n_components=3;, score=23.786 total time=   0.3s
[CV 4/6] END ...................n_components=3;, score=24.914 total time=   0.3s
[CV 5/6] END ...................n_components=3;, score=22.474 total time=   0.3s
[CV 6/6] END ...................n_components=3;, score=23.684 total time=   0.2s
[CV 1/6] END ...................n_components=4;, score=26.966 total time=   0.3s
[CV 2/6] END ...................n_components=4;, score=25.554 total time=   0.4s
[CV 3/6] END ...................n_components=4;, score=27.663 total time=   0.3s
[CV 4/6] END ...................n_components=4;, score=28.409 total time=   0.3s
[CV 5/6] END ...................n_components=4;, score=28.691 total time=   0.3s
[CV 6/6] END ...................n_components=4;, score=26.965 total time=   0.8s
hyperparameter tuning for Gaussian Mixture Model:

Best score of model:
27.37461665798462 

Best params of model:
{'n_components': 4} 

Best estimator of model:
GaussianMixture(n_components=4) 

--------------------------------------------
Initialization 0
Initialization converged: True
Classification Reports of all models in training phase:

Classification Report for Logistic Regression:

              precision    recall  f1-score   support

           0       0.83      0.97      0.89      6373
           1       0.64      0.22      0.33      1627

    accuracy                           0.82      8000
   macro avg       0.73      0.60      0.61      8000
weighted avg       0.79      0.82      0.78      8000

--------------------------------------------
Classification Report for SVM:

              precision    recall  f1-score   support

           0       0.87      0.98      0.92      6373
           1       0.84      0.41      0.55      1627

    accuracy                           0.86      8000
   macro avg       0.85      0.69      0.73      8000
weighted avg       0.86      0.86      0.84      8000

--------------------------------------------
Classification Report for Dtree:

              precision    recall  f1-score   support

           0       0.90      0.97      0.93      6373
           1       0.82      0.57      0.68      1627

    accuracy                           0.89      8000
   macro avg       0.86      0.77      0.80      8000
weighted avg       0.88      0.89      0.88      8000

--------------------------------------------
Classification Report for KNN:

              precision    recall  f1-score   support

           0       0.88      0.97      0.92      6373
           1       0.78      0.47      0.59      1627

    accuracy                           0.87      8000
   macro avg       0.83      0.72      0.75      8000
weighted avg       0.86      0.87      0.85      8000

--------------------------------------------
Classification Report for Random Forest:

              precision    recall  f1-score   support

           0       0.89      0.98      0.93      6373
           1       0.87      0.53      0.66      1627

    accuracy                           0.89      8000
   macro avg       0.88      0.75      0.80      8000
weighted avg       0.89      0.89      0.88      8000

--------------------------------------------
Classification Report for XGB:

              precision    recall  f1-score   support

           0       0.90      0.97      0.94      6373
           1       0.85      0.58      0.69      1627

    accuracy                           0.89      8000
   macro avg       0.88      0.78      0.81      8000
weighted avg       0.89      0.89      0.89      8000

--------------------------------------------
Classification Report for GMM:

              precision    recall  f1-score   support

           0       1.00      1.00      1.00      7963

    accuracy                           1.00      7963
   macro avg       1.00      1.00      1.00      7963
weighted avg       1.00      1.00      1.00      7963

--------------------------------------------
Test Phase:

(1992, 17)
Evaluation parameters for Random Forest:

ROC AUC Score: 0.6884046107248932
Confusion Matrix:
 [[1537   46]
 [ 243  166]]
Accuracy Score: 0.8549196787148594
Precision Score: 0.7830188679245284
Classification Report:
               precision    recall  f1-score   support

           0       0.86      0.97      0.91      1583
           1       0.78      0.41      0.53       409

    accuracy                           0.85      1992
   macro avg       0.82      0.69      0.72      1992
weighted avg       0.85      0.85      0.84      1992

--------------------------------------------
Evaluation parameters for XGB:

ROC AUC Score: 0.6947101461586818
Confusion Matrix:
 [[1526   57]
 [ 235  174]]
Accuracy Score: 0.8534136546184738
Precision Score: 0.7532467532467533
Classification Report:
               precision    recall  f1-score   support

           0       0.87      0.96      0.91      1583
           1       0.75      0.43      0.54       409

    accuracy                           0.85      1992
   macro avg       0.81      0.69      0.73      1992
weighted avg       0.84      0.85      0.84      1992

--------------------------------------------
Evaluation parameters for Dtree:

ROC AUC Score: 0.6947866002931514
Confusion Matrix:
 [[1414  169]
 [ 206  203]]
Accuracy Score: 0.8117469879518072
Precision Score: 0.5456989247311828
Classification Report:
               precision    recall  f1-score   support

           0       0.87      0.89      0.88      1583
           1       0.55      0.50      0.52       409

    accuracy                           0.81      1992
   macro avg       0.71      0.69      0.70      1992
weighted avg       0.81      0.81      0.81      1992

--------------------------------------------
Getting infos for GMM thresholds and score in test phase:

[  -4.35853357  -11.30653154   -0.2634025  ... -165.33113181 -217.11770541
  -38.69792073]
The threshold of the score is -161.39
[0 0 0 ... 1 1 0]
--------------------------------------------
